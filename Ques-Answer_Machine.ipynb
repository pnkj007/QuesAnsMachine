{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "\n",
    "class QuestionAnsweringModel:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased',return_token_type_ids = True)\n",
    "        self.model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased-distilled-squad')\n",
    "\n",
    "    def encode(self,question,context):\n",
    "        encoded = self.tokenizer.encode_plus(question, context)\n",
    "        return encoded[\"input_ids\"], encoded[\"attention_mask\"]\n",
    "\n",
    "    def decode(self,token):\n",
    "        answer_tokens = self.tokenizer.convert_ids_to_tokens(token , skip_special_tokens=True)\n",
    "        return self.tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "\n",
    "    def predict(self,question,context):\n",
    "        input_ids, attention_mask = self.encode(question,context)\n",
    "        start_scores, end_scores = self.model(torch.tensor([input_ids]), attention_mask=torch.tensor([attention_mask]))\n",
    "        ans_tokens = input_ids[torch.argmax(start_scores) : torch.argmax(end_scores)+1]\n",
    "        answer = self.decode(ans_tokens)\n",
    "        return answer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_model = QuestionAnsweringModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(QA_model, '/Anaconda3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torch.load('/Anaconda3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-c14c5ee82961>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "model1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toshi\\Anaconda3\\envs\\R_env\\lib\\site-packages\\torch\\storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "with open('QuesAnsModel','wb') as file:\n",
    "    pickle.dump(QA_model,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"We introduce a new language representation model called BERT, which stands for\n",
    "Bidirectional Encoder Representations from Transformers. Unlike recent language\n",
    "representation models (Peters et al., 2018a; Radford et al., 2018), BERT is\n",
    "designed to pretrain deep bidirectional representations from unlabeled text by\n",
    "jointly conditioning on both left and right context in all layers. As a result,\n",
    "the pre-trained BERT model can be finetuned with just one additional output\n",
    "layer to create state-of-the-art models for a wide range of tasks, such as\n",
    "question answering and language inference, without substantial taskspecific\n",
    "architecture modifications. BERT is conceptually simple and empirically\n",
    "powerful. It obtains new state-of-the-art results on eleven natural language\n",
    "processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute\n",
    "improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1\n",
    "question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD\n",
    "v2.0 Test F1 to 83.1 (5.1 point absolute improvement).\"\"\"\n",
    "\n",
    "question_one = \"What is BERTs best score on Squadv2 ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"Narendra Damodardas Modi (Gujarati pronunciation: [ˈnəɾendrə dɑmodəɾˈdɑs ˈmodiː] (About this soundlisten); \n",
    "born 17 September 1950) is an Indian politician serving as the 14th and current Prime Minister of India since 2014.\n",
    "He was the Chief Minister of Gujarat from 2001 to 2014 and is the Member of Parliament for Varanasi. \n",
    "Modi is a member of the Bharatiya Janata Party (BJP) and of the Rashtriya Swayamsevak Sangh (RSS),\n",
    "a Hindu nationalist volunteer organisation. He is the first prime minister outside of the Indian National \n",
    "Congress to win two consecutive terms with a full majority and the second to complete five years in office after \n",
    "Atal Bihari Vajpayee.[2]\n",
    "\n",
    "Born to a Gujarati family in Vadnagar, Modi helped his father sell tea as a child and has said he later ran his own stall.\n",
    "He was introduced to the RSS at the age of eight, beginning a long association with the organisation. Modi left home after \n",
    "finishing high-school in part due to child marriage to Jashodaben Chimanlal Modi, which he abandoned and publicly acknowledged\n",
    "only many decades later. Modi travelled around India for two years and visited a number of religious centres before returning \n",
    "to Gujarat. In 1971 he became a full-time worker for the RSS. During the state of emergency imposed across the country in 1975,\n",
    "Modi was forced to go into hiding. The RSS assigned him to the BJP in 1985 and he held several positions within the party \n",
    "hierarchy until 2001, rising to the rank of general secretary.\n",
    "\n",
    "Modi was appointed Chief Minister (CM) of Gujarat in 2001 due to Keshubhai Patel's failing health and poor public image \n",
    "following the earthquake in Bhuj. Modi was elected to the legislative assembly soon after. His administration has been \n",
    "considered complicit in the 2002 Gujarat riots,[a] or otherwise criticised for its handling of it. A Supreme Court-appointed\n",
    "Special Investigation Team found no evidence to initiate prosecution proceedings against Modi personally.[b] His policies as\n",
    "chief minister, credited with encouraging economic growth, have received praise.[10] His administration has been criticised \n",
    "for failing to significantly improve health, poverty and education indices in the state.[c]\"\"\"\n",
    "\n",
    "question_one = \"Who is narendra modi ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you want to ask a ques, please enter Yes else No!!yes\n",
      "Ques:How old are Margie and Tommy?\n",
      "Ans: 13\n",
      "If you want to ask a ques, please enter Yes else No!!How old are Margie?\n",
      "Another one? yes/no > yes\n",
      "Ques:How old are Margie?\n",
      "Ans: 11 years of age\n",
      "If you want to ask a ques, please enter Yes else No!!yes\n",
      "Ques:Had Margie ever seen a book before?\n",
      "Ans: margie ’ s grandfather had once told her that when he was young his own grandfather had told him that there was a time when all stories were printed on paper . margie says that the pages of the book had turned yellow , and they had been crushed as it was very old\n",
      "If you want to ask a ques, please enter Yes else No!!yes\n",
      "Ques: What things about the book did she find strange?\n",
      "Ans: real books do not exist\n",
      "If you want to ask a ques, please enter Yes else No!!no\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    cont = input(\"If you want to ask a ques, please enter Yes else No!!\")\n",
    "    while cont.lower() not in (\"yes\",\"no\"):\n",
    "        cont = input(\"Another one? yes/no > \")\n",
    "    if cont == \"no\":\n",
    "        break\n",
    "    else:\n",
    "        question_one = input('Ques:')\n",
    "        print('Ans:',model.predict(question_one,book_context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'QuestionAnsweringModel' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-658821fb2a6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'QuesAnsModel'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'QuestionAnsweringModel' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "m = pickle.load(open('QuesAnsModel','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'17 september 1950'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(\"when modi born\",context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'rb') as f:\n",
    "        pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
